{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10485760it [02:23, 73118.59it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import requests\n",
    "\n",
    "url = \"http://download.thinkbroadband.com/10MB.zip\"\n",
    "response = requests.get(url, stream=True)\n",
    "\n",
    "with open(\"10MB\", \"wb\") as handle:\n",
    "    for data in tqdm(response.iter_content()):\n",
    "        handle.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def split_files(src, train, valid, ratio=.8):\n",
    "    \n",
    "    # make directory everytime\n",
    "    os.makedirs(src, exist_ok=True)\n",
    "    os.makedirs(train, exist_ok=True)\n",
    "    os.makedirs(valid, exist_ok=True)\n",
    "    \n",
    "    src_files = os.listdir(src)\n",
    "    for idx, file_name in enumerate(src_files):\n",
    "        full_file_name = os.path.join(src, file_name)\n",
    "        if os.path.isfile(full_file_name):\n",
    "                if idx < len(src_files)*ratio:\n",
    "                    shutil.copy(full_file_name, train)\n",
    "                else:\n",
    "                    shutil.copy(full_file_name, valid)\n",
    "                    \n",
    "# keep dir clean before copy files\n",
    "sub_src = '../data/lenses/sub'\n",
    "sub_train = '../data/lenses_train/sub'\n",
    "sub_valid = '../data/lenses_valid/sub'\n",
    "split_files(sub_src, sub_train, sub_valid, .8)\n",
    "\n",
    "no_sub_src = '../data/lenses/no_sub'\n",
    "no_sub_train = '../data/lenses_train/no_sub'\n",
    "no_sub_valid = '../data/lenses_valid/no_sub'\n",
    "split_files(no_sub_src, no_sub_train, no_sub_valid, .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "#         transforms.RandomResizedCrop(150),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "train_dataset = datasets.ImageFolder(root='../data/lenses_train',\n",
    "                                           transform=data_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                             batch_size=8, shuffle=True,\n",
    "                                             num_workers=4)\n",
    "\n",
    "valid_dataset = datasets.ImageFolder(root='../data/lenses_valid',\n",
    "                                           transform=data_transform)\n",
    "valid_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                             batch_size=8, shuffle=True,\n",
    "                                             num_workers=4)\n",
    "\n",
    "classes = ('no_sub', 'sub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sub      sub      sub      sub      sub   no_sub      sub      sub\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# print labels\n",
    "print(' '.join('%8s' % classes[labels[j]] for j in range(8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LensesCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 34 * 34, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), 16 * 34 * 34)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01,\\\n",
    "#                                         steps_per_epoch=len(train_loader),\\\n",
    "#                                         epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.069\n",
      "[1,   200] loss: 0.069\n",
      "[1,   300] loss: 0.069\n",
      "[1,   400] loss: 0.069\n",
      "[1,   500] loss: 0.069\n",
      "[1,   600] loss: 0.069\n",
      "[1,   700] loss: 0.069\n",
      "[1,   800] loss: 0.069\n",
      "[1,   900] loss: 0.069\n",
      "[1,  1000] loss: 0.069\n",
      "[2,   100] loss: 0.069\n",
      "[2,   200] loss: 0.069\n",
      "[2,   300] loss: 0.069\n",
      "[2,   400] loss: 0.069\n",
      "[2,   500] loss: 0.069\n",
      "[2,   600] loss: 0.069\n",
      "[2,   700] loss: 0.069\n",
      "[2,   800] loss: 0.069\n",
      "[2,   900] loss: 0.069\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-6c896e80b1bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-18c95cb038a7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m34\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m34\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(3):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 1000))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "#         scheduler.step()\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './lenses_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(valid_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(8)))\n",
    "\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "outputs = net(images)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in valid_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
